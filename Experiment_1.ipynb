{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTbr0Gau+XPsT7d/U09WNx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John-D-Boom/geom_virtual_nodes/blob/main/Experiment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ge_T_JVWpB9",
        "outputId": "8c5020d4-5744-4c7e-efb4-463497ae653a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing scatter\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling sparse\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling pytorch geometric\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing rdkit\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling py3Dmol\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Install geometric and chem modules\n",
        "import os\n",
        "import torch\n",
        "assert torch.cuda.is_available(), \"WARNING! You are running on a non-GPU instance. For this practical a GPU is highly recommended.\"\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print('Installing scatter')\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "    print('Installing sparse')\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "    # print('Installing cluster')\n",
        "    # !pip install -q torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "    print('Installing pytorch geometric')\n",
        "    !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "    print('Installing rdkit')\n",
        "    !pip install -q rdkit-pypi==2021.9.4\n",
        "    print('Installing py3Dmol')\n",
        "    !pip install -q py3Dmol\n",
        "else:\n",
        "    print('already installed. Not repeating')\n",
        "    print('To uninstall: !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Import python modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "from scipy.stats import ortho_group\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import ClusterData\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.datasets import QM9\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_scatter import scatter\n",
        "\n",
        "import rdkit.Chem as Chem\n",
        "from rdkit.Geometry.rdGeometry import Point3D\n",
        "from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "import py3Dmol\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA6pkef_XI3p",
        "outputId": "988e0a24-32fe-4706-f94d-d5e7d0758d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n",
            "PyTorch version 2.0.0+cu118\n",
            "PyG version 2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5PpKUK2XKzJ",
        "outputId": "67b13a3f-3dbd-4b32-d4da-65fd71a8769d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper functions for data preparation\n",
        "\n",
        "class SetTarget:\n",
        "    \"\"\"\n",
        "    This transform modifies the labels vector per data sample to only keep \n",
        "    the label for a specific target (there are 19 targets in QM9).\n",
        "\n",
        "    Note: for this practical, we have hardcoded the target to be target #0,\n",
        "    i.e. the electric dipole moment of a drug-like molecule.\n",
        "    (https://en.wikipedia.org/wiki/Electric_dipole_moment)\n",
        "    \"\"\"\n",
        "    def __call__(self, data):\n",
        "        target = 0 # we hardcoded choice of target  \n",
        "        data.y = data.y[:, target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class CompleteGraph:\n",
        "    \"\"\"\n",
        "    This transform adds all pairwise edges into the edge index per data sample, \n",
        "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
        "    \"\"\"\n",
        "    def __call__(self, data):\n",
        "        device = data.edge_index.device\n",
        "\n",
        "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
        "        col = col.repeat(data.num_nodes)\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "        edge_attr = None\n",
        "        if data.edge_attr is not None:\n",
        "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
        "            size = list(data.edge_attr.size())\n",
        "            size[0] = data.num_nodes * data.num_nodes\n",
        "            edge_attr = data.edge_attr.new_zeros(size)\n",
        "            edge_attr[idx] = data.edge_attr\n",
        "\n",
        "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "        data.edge_attr = edge_attr\n",
        "        data.edge_index = edge_index\n",
        "\n",
        "        return data\n",
        "\n",
        "print(\"Helper functions loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEqsiW9hXOvz",
        "outputId": "879ac75d-9608-4bee-88ce-3d40c6f38a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper functions for visualization\n",
        "\n",
        "allowable_atoms = [\n",
        "    \"H\",\n",
        "    \"C\",\n",
        "    \"N\",\n",
        "    \"O\",\n",
        "    \"F\",\n",
        "    \"C\",\n",
        "    \"Cl\",\n",
        "    \"Br\",\n",
        "    \"I\",\n",
        "    \"H\", \n",
        "    \"Unknown\",\n",
        "]\n",
        "\n",
        "def to_atom(t):\n",
        "    try:\n",
        "        return allowable_atoms[int(t.argmax())]\n",
        "    except:\n",
        "        return \"C\"\n",
        "\n",
        "\n",
        "def to_bond_index(t):\n",
        "    t_s = t.squeeze()\n",
        "    return [1, 2, 3, 4][\n",
        "        int(\n",
        "            torch.dot(\n",
        "                t_s,\n",
        "                torch.tensor(\n",
        "                    range(t_s.size()[0]), dtype=torch.float, device=t.device\n",
        "                ),\n",
        "            ).item()\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def to_rdkit(data, device=None):\n",
        "    has_pos = False\n",
        "    node_list = []\n",
        "    for i in range(data.x.size()[0]):\n",
        "        node_list.append(to_atom(data.x[i][:5]))\n",
        "\n",
        "    # create empty editable mol object\n",
        "    mol = Chem.RWMol()\n",
        "    # add atoms to mol and keep track of index\n",
        "    node_to_idx = {}\n",
        "    invalid_idx = set([])\n",
        "    for i in range(len(node_list)):\n",
        "        if node_list[i] == \"Stop\" or node_list[i] == \"H\":\n",
        "            invalid_idx.add(i)\n",
        "            continue\n",
        "        a = Chem.Atom(node_list[i])\n",
        "        molIdx = mol.AddAtom(a)\n",
        "        node_to_idx[i] = molIdx\n",
        "\n",
        "    added_bonds = set([])\n",
        "    for i in range(0, data.edge_index.size()[1]):\n",
        "        ix = data.edge_index[0][i].item()\n",
        "        iy = data.edge_index[1][i].item()\n",
        "        bond = to_bond_index(data.edge_attr[i])  # <font color='red'>TODO</font> fix this\n",
        "        # bond = 1\n",
        "        # add bonds between adjacent atoms\n",
        "\n",
        "        if data.edge_attr[i].sum() == 0:\n",
        "          continue\n",
        "\n",
        "        if (\n",
        "            (str((ix, iy)) in added_bonds)\n",
        "            or (str((iy, ix)) in added_bonds)\n",
        "            or (iy in invalid_idx or ix in invalid_idx)\n",
        "        ):\n",
        "            continue\n",
        "        # add relevant bond type (there are many more of these)\n",
        "\n",
        "        if bond == 0:\n",
        "            continue\n",
        "        elif bond == 1:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 2:\n",
        "            bond_type = Chem.rdchem.BondType.DOUBLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 3:\n",
        "            bond_type = Chem.rdchem.BondType.TRIPLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 4:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "\n",
        "        added_bonds.add(str((ix, iy)))\n",
        "\n",
        "    if has_pos:\n",
        "        conf = Chem.Conformer(mol.GetNumAtoms())\n",
        "        for i in range(data.pos.size(0)):\n",
        "            if i in invalid_idx:\n",
        "                continue\n",
        "            p = Point3D(\n",
        "                data.pos[i][0].item(),\n",
        "                data.pos[i][1].item(),\n",
        "                data.pos[i][2].item(),\n",
        "            )\n",
        "            conf.SetAtomPosition(node_to_idx[i], p)\n",
        "        conf.SetId(0)\n",
        "        mol.AddConformer(conf)\n",
        "\n",
        "    # Convert RWMol to Mol object\n",
        "    mol = mol.GetMol()\n",
        "    mol_frags = rdmolops.GetMolFrags(mol, asMols=True, sanitizeFrags=False)\n",
        "    largest_mol = max(mol_frags, default=mol, key=lambda m: m.GetNumAtoms())\n",
        "    return largest_mol\n",
        "\n",
        "\n",
        "def MolTo3DView(mol, size=(300, 300), style=\"stick\", surface=False, opacity=0.5):\n",
        "    \"\"\"Draw molecule in 3D\n",
        "    \n",
        "    Args:\n",
        "    ----\n",
        "        mol: rdMol, molecule to show\n",
        "        size: tuple(int, int), canvas size\n",
        "        style: str, type of drawing molecule\n",
        "               style can be 'line', 'stick', 'sphere', 'carton'\n",
        "        surface, bool, display SAS\n",
        "        opacity, float, opacity of surface, range 0.0-1.0\n",
        "    Return:\n",
        "    ----\n",
        "        viewer: py3Dmol.view, a class for constructing embedded 3Dmol.js views in ipython notebooks.\n",
        "    \"\"\"\n",
        "    assert style in ('line', 'stick', 'sphere', 'carton')\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol)\n",
        "    AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "    mblock = Chem.MolToMolBlock(mol)\n",
        "    viewer = py3Dmol.view(width=size[0], height=size[1])\n",
        "    viewer.addModel(mblock, 'mol')\n",
        "    viewer.setStyle({style:{}})\n",
        "    if surface:\n",
        "        viewer.addSurface(py3Dmol.SAS, {'opacity': opacity})\n",
        "    viewer.zoomTo()\n",
        "    return viewer\n",
        "\n",
        "def smi2conf(smiles):\n",
        "    '''Convert SMILES to rdkit.Mol with 3D coordinates'''\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        mol = Chem.AddHs(mol)\n",
        "        AllChem.EmbedMolecule(mol)\n",
        "        AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "        return mol\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "print(\"Helper functions added.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5RXjOw2XVs7",
        "outputId": "44ecd6cc-126c-47bd-d404-130cce4af4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions added.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper functions for managing experiments, training, and evaluating models.\n",
        "\n",
        "def train(model, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(data)\n",
        "        loss = F.mse_loss(y_pred, data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def eval(model, loader, device):\n",
        "    model.eval()\n",
        "    error = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(data)\n",
        "            # Mean Absolute Error using std (computed when preparing data)\n",
        "            error += (y_pred * std - data.y * std).abs().sum().item()\n",
        "    return error / len(loader.dataset)\n",
        "\n",
        "\n",
        "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100):\n",
        "    \n",
        "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(\"\\nModel architecture:\")\n",
        "    print(model)\n",
        "    total_param = 0\n",
        "    for param in model.parameters():\n",
        "        total_param += np.prod(list(param.data.size()))\n",
        "    print(f'Total parameters: {total_param}')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Adam optimizer with LR 1e-3\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # LR scheduler which decays LR when validation metric doesn't improve\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
        "    \n",
        "    print(\"\\nStart training:\")\n",
        "    best_val_error = None\n",
        "    perf_per_epoch = [] # Track Test/Val MAE vs. epoch (for plotting)\n",
        "    t = time.time()\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # Call LR scheduler at start of each epoch\n",
        "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Train model for one epoch, return avg. training loss\n",
        "        loss = train(model, train_loader, optimizer, device)\n",
        "        \n",
        "        # Evaluate model on validation set\n",
        "        val_error = eval(model, val_loader, device)\n",
        "        \n",
        "        if best_val_error is None or val_error <= best_val_error:\n",
        "            # Evaluate model on test set if validation metric improves\n",
        "            test_error = eval(model, test_loader, device)\n",
        "            best_val_error = val_error\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            # Print and track stats every 10 epochs\n",
        "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
        "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
        "        \n",
        "        scheduler.step(val_error)\n",
        "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
        "    \n",
        "    t = time.time() - t\n",
        "    train_time = t/60\n",
        "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
        "    \n",
        "    return best_val_error, test_error, train_time, perf_per_epoch"
      ],
      "metadata": {
        "id": "FIVjzXzeUJ0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Total number of samples: {len(dataset)}.\")\n",
        "\n",
        "# # Split datasets (in case of using the full dataset)\n",
        "# # test_dataset = dataset[:10000]\n",
        "# # val_dataset = dataset[10000:20000]\n",
        "# # train_dataset = dataset[20000:]\n",
        "\n",
        "# # Split datasets (our 3K subset)\n",
        "# train_dataset = dataset[:1000]\n",
        "# val_dataset = dataset[1000:2000]\n",
        "# test_dataset = dataset[2000:3000]\n",
        "# print(f\"Created dataset splits with {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test samples.\")\n",
        "\n",
        "# # Create dataloaders with batch size = 32\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "izf-3PkGYapE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper function for visualizing molecules with virtual nodes\n",
        "import plotly.graph_objects as go\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "import networkx as nx\n",
        "def plot_molecule_3d(molecule):\n",
        "    G = to_networkx(molecule)\n",
        "    pos = nx.spring_layout(G, dim=3)\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edge_z = []\n",
        "    for edge in G.edges():\n",
        "        x0, y0, z0 = pos[edge[0]]\n",
        "        x1, y1, z1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "        edge_z.extend([z0, z1, None])\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_z = []\n",
        "    node_color = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y, z = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        node_z.append(z)\n",
        "\n",
        "        # Use the first 5 features of the x tensor as a one-hot encoding of the atom identity\n",
        "        if molecule.x.shape[1] == 11:\n",
        "            atom_identity = torch.argmax(molecule.x[node][:5]).item()\n",
        "        elif molecule.x.shape[1] == 12:\n",
        "            atom_identity = torch.argmax(molecule.x[node][:6]).item()\n",
        "        else:\n",
        "            print(\"ERROR: molecule.x has unrecognized dimensions (should be 11 or 12) and so number of atom types cannot be determined\")\n",
        "            return\n",
        "        # Map the atom identity to a color\n",
        "        if atom_identity == 0:\n",
        "            color = 'white' # H\n",
        "        elif atom_identity == 1:\n",
        "            color = 'black' # C\n",
        "        elif atom_identity == 2:\n",
        "            color = 'blue' # N\n",
        "        elif atom_identity == 3:\n",
        "            color = 'red' # O\n",
        "        elif atom_identity == 4:\n",
        "            color = 'purple' # F\n",
        "        elif atom_identity == 5:\n",
        "            color = 'green' # Virtual Node\n",
        "        else:\n",
        "            print('Unrecognized molecule type')\n",
        "            color = 'pink' \n",
        "        node_color.append(color)\n",
        "    node_trace = go.Scatter3d(x=node_x, y=node_y, z=node_z, mode='markers', \n",
        "                                marker=dict(size=8, color=node_color))\n",
        "    edge_trace = go.Scatter3d(x=edge_x, y=edge_y, z=edge_z, mode='lines', \n",
        "                                line=dict(color='black', width=1), hoverinfo='none')\n",
        "    fig = go.Figure(data=[edge_trace, node_trace], layout=go.Layout(\n",
        "        margin=dict(l=0, r=0, b=0, t=0),\n",
        "        scene=dict(xaxis=dict(title='', showticklabels=False, showgrid=False, zeroline=False),\n",
        "                    yaxis=dict(title='', showticklabels=False, showgrid=False, zeroline=False),\n",
        "                    zaxis=dict(title='', showticklabels=False, showgrid=False, zeroline=False)),\n",
        "        showlegend=False))\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "Xi5X0RbFYgtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper Function to add virtual nodes\n",
        "def add_virtual_one_hot(tensor):\n",
        "    # Get the shape of the input tensor\n",
        "    n, m = tensor.shape\n",
        "    assert m == 11, \"input tensor should have 11 features, just like atom3d dataset. found {}\".format(m)\n",
        "    new_tensor = torch.zeros((n, 12))\n",
        "    new_tensor[:, :5] = tensor[:, :5]\n",
        "    new_tensor[:, 6:] = tensor[:, 5:]\n",
        "    return new_tensor\n",
        "\n",
        "def add_virtual_node(graph_in: torch_geometric.data.Data, nodes_to_connect: list):\n",
        "\n",
        "\n",
        "    graph = copy.copy(graph_in)\n",
        "    #Node will be appended to the end of the array\n",
        "    virtual_index = len(graph.x) \n",
        "\n",
        "    #Pad the features with an extra one hot column in the 6th position to \n",
        "    #indicate the virtual node\n",
        "    #Only do this if no virtual nodes have been added before\n",
        "    if graph.x.shape[1] == 11:\n",
        "        graph.x = add_virtual_one_hot(graph.x)\n",
        "\n",
        "    #Add node to x features\n",
        "    new_node_x = torch.zeros((1,12))\n",
        "    new_node_x[0,5] = 1\n",
        "    graph.x = torch.cat([graph.x, new_node_x], dim=0)\n",
        "    assert graph.x.shape[0] == virtual_index + 1, print(graph.x.shape)\n",
        "\n",
        "    #Add edges connecting the node to nodes_to_connect\n",
        "    new_edges = [[], []]\n",
        "    for node in nodes_to_connect:\n",
        "        assert node >= 0\n",
        "        assert node < len(graph.x-1) #node must have been possible in orig graph\n",
        "\n",
        "        #Add edge in both directions\n",
        "        new_edges[0].append(virtual_index)\n",
        "        new_edges[1].append(node)\n",
        "\n",
        "        new_edges[0].append(node)\n",
        "        new_edges[1].append(virtual_index)\n",
        "\n",
        "    #Add edges connecting the virtual node to all other virtual nodes\n",
        "    # 1. get list of the nodes with virtual_node identifier\n",
        "    # 2. Fully connect it\n",
        "\n",
        "    virtual_indices = torch.nonzero(graph.x[:-1, 5] == 1, as_tuple=False) #:-1 to not include itself\n",
        "    for idx in virtual_indices:\n",
        "        node = int(idx[0])\n",
        "        assert node >= 0\n",
        "        assert node < len(graph.x-1)\n",
        "        assert node != virtual_index\n",
        "        new_edges[0].append(virtual_index)\n",
        "        new_edges[1].append(node)\n",
        "\n",
        "        new_edges[0].append(node)\n",
        "        new_edges[1].append(virtual_index)\n",
        "\n",
        "    graph.edge_index = torch.cat([graph.edge_index, torch.tensor(new_edges)], dim = 1)\n",
        "\n",
        "\n",
        "    #Add a position to node based on arithmetic mean of positions\n",
        "    virtual_pos = torch.zeros((1,3))\n",
        "    for node in nodes_to_connect:\n",
        "        assert node >= 0\n",
        "        assert node < len(graph.x-1) #node must have been possible in orig graph\n",
        "        virtual_pos = virtual_pos + graph.pos[node]\n",
        "    virtual_pos = virtual_pos / (virtual_index-1)\n",
        "    graph.pos = torch.cat([graph.pos, virtual_pos])\n",
        "    \n",
        "    #update z just cuz\n",
        "    graph.z = torch.cat([graph.z, torch.tensor([0])])\n",
        "\n",
        "    #update edge_attributes to be \"single\" bonds. Currently my MPNN won't \n",
        "    #analyze the actual bonds so it doesn't matter. However, this might help it \n",
        "    #plot and will ensure consistency\n",
        "    new_edge_attr = torch.zeros((len(new_edges[0])), 4)\n",
        "    new_edge_attr[:, 0] = 1\n",
        "    graph.edge_attr = torch.cat([graph.edge_attr, new_edge_attr], dim = 0)\n",
        "        \n",
        "    return graph"
      ],
      "metadata": {
        "id": "0loW3PaAaRFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper Function to use to assign nodes to a virtual node with METIS Clustering\n",
        "def get_clusters(data:torch_geometric.data.Data, num_clusters: int):\n",
        "\n",
        "    cluster_data = ClusterData(data, num_parts=num_clusters, recursive=False, log=False)\n",
        "    \n",
        "    clusters = {} #key: cluster_number | value: list of nodes in that cluster\n",
        "    for i, cluster in enumerate(cluster_data):\n",
        "        clusters[i] = []\n",
        "        for node_pos in cluster.pos:\n",
        "            node_index = int(torch.nonzero(torch.eq(node_pos, data.pos).all(dim=1))[0][0])\n",
        "            clusters[i].append(node_index)\n",
        "\n",
        "    return clusters"
      ],
      "metadata": {
        "id": "YV4XxsyJaaQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddVirtualNodes:\n",
        "    \"\"\"\n",
        "    This transform adds up to 5 virtual nodes, depending on the number of input nodes\n",
        "    It uses METIS clustering to assign each node to a cluster, then fully connects\n",
        "    the virtual node to each cluster. Then, the virtual nodes are fully connected to\n",
        "    each other.\n",
        "\n",
        "    At least one virtual node is added to all molecules.  A virtual node is added for each 8 atoms in the dataset.\n",
        "    8 atoms was chosen b/c that, on average, adds 3 nodes to each molecule. \n",
        "    Visually plotting results on 20 molecules selected at random showed that the\n",
        "    clusters appeared to match chemical intuition.\n",
        "    \"\"\"\n",
        "    def __call__(self, data):\n",
        "        num_atoms = len(data.x)\n",
        "        assert num_atoms>0, \"Error: data should have more than 0 atoms\"\n",
        "\n",
        "        num_clusters = (num_atoms // 8) + 1\n",
        "\n",
        "        clusters = get_clusters(data, num_clusters)\n",
        "        new_data = data\n",
        "        for node_list in clusters.values():\n",
        "            new_data = add_virtual_node(new_data, node_list)\n",
        "        \n",
        "        return new_data"
      ],
      "metadata": {
        "id": "b3C1g-GNbJLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Download Dataset\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    path = './qm9'\n",
        "    target = 0\n",
        "\n",
        "    # Transforms which are applied during data loading:\n",
        "    # (1) Fully connect the graphs, (2) Select the target/label\n",
        "    # transform = T.Compose([CompleteGraph(), SetTarget()])\n",
        "    transform = T.Compose([SetTarget(), AddVirtualNodes()]) #Removed CompleteGraph() to stop having them be fully connected\n",
        "    \n",
        "    # Load the QM9 dataset with the transforms defined\n",
        "    dataset = QM9(path, transform=transform)\n",
        "\n",
        "    # Normalize targets per data sample to mean = 0 and std = 1.\n",
        "    mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
        "    std = dataset.data.y.std(dim=0, keepdim=True)\n",
        "    dataset.data.y = (dataset.data.y - mean) / std\n",
        "    mean, std = mean[:, target].item(), std[:, target].item()"
      ],
      "metadata": {
        "id": "EzoJBs9za2Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_molecule_3d(dataset[1001])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "K_6gHP3fiMtG",
        "outputId": "461543fe-f5dc-49f0-bb84-b0d52182d1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"1cac08ef-2170-49ed-a98a-751371a6a7c0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1cac08ef-2170-49ed-a98a-751371a6a7c0\")) {                    Plotly.newPlot(                        \"1cac08ef-2170-49ed-a98a-751371a6a7c0\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"black\",\"width\":1},\"mode\":\"lines\",\"x\":[0.7537469406528274,0.28449980640302397,null,0.7537469406528274,0.28077532901629837,null,0.28449980640302397,0.7537469406528274,null,0.28449980640302397,-0.1268474548111234,null,0.28449980640302397,0.4533579629569477,null,0.28449980640302397,0.28077532901629837,null,-0.1268474548111234,0.28449980640302397,null,-0.1268474548111234,-0.3868052026309772,null,-0.1268474548111234,-0.10926408143000026,null,-0.1268474548111234,0.28077532901629837,null,-0.3868052026309772,-0.1268474548111234,null,-0.3868052026309772,-0.581799218046257,null,-0.3868052026309772,-0.22571230727795144,null,-0.3868052026309772,-0.07455315970262265,null,-0.581799218046257,-0.3868052026309772,null,-0.581799218046257,-0.26180742500821713,null,-0.581799218046257,-0.07455315970262265,null,-0.26180742500821713,-0.581799218046257,null,-0.26180742500821713,-0.10926408143000026,null,-0.26180742500821713,-0.005591190121949286,null,-0.26180742500821713,-0.07455315970262265,null,-0.10926408143000026,-0.1268474548111234,null,-0.10926408143000026,-0.26180742500821713,null,-0.10926408143000026,0.28077532901629837,null,0.4533579629569477,0.28449980640302397,null,0.4533579629569477,0.28077532901629837,null,-0.22571230727795144,-0.3868052026309772,null,-0.22571230727795144,-0.07455315970262265,null,-0.005591190121949286,-0.26180742500821713,null,-0.005591190121949286,-0.07455315970262265,null,0.28077532901629837,0.7537469406528274,null,0.28077532901629837,0.28449980640302397,null,0.28077532901629837,-0.1268474548111234,null,0.28077532901629837,-0.10926408143000026,null,0.28077532901629837,0.4533579629569477,null,0.28077532901629837,-0.07455315970262265,null,-0.07455315970262265,-0.3868052026309772,null,-0.07455315970262265,-0.581799218046257,null,-0.07455315970262265,-0.26180742500821713,null,-0.07455315970262265,-0.22571230727795144,null,-0.07455315970262265,-0.005591190121949286,null,-0.07455315970262265,0.28077532901629837,null],\"y\":[0.764172420550459,0.7014446684711804,null,0.764172420550459,0.25287550776780127,null,0.7014446684711804,0.764172420550459,null,0.7014446684711804,0.37221047797551327,null,0.7014446684711804,0.5177866385883513,null,0.7014446684711804,0.25287550776780127,null,0.37221047797551327,0.7014446684711804,null,0.37221047797551327,0.08706232050097786,null,0.37221047797551327,-0.20849278397401433,null,0.37221047797551327,0.25287550776780127,null,0.08706232050097786,0.37221047797551327,null,0.08706232050097786,-0.4626679443606493,null,0.08706232050097786,-0.03156946660036224,null,0.08706232050097786,-0.29568439013002074,null,-0.4626679443606493,0.08706232050097786,null,-0.4626679443606493,-0.7057672031932883,null,-0.4626679443606493,-0.29568439013002074,null,-0.7057672031932883,-0.4626679443606493,null,-0.7057672031932883,-0.20849278397401433,null,-0.7057672031932883,-0.9913702455959488,null,-0.7057672031932883,-0.29568439013002074,null,-0.20849278397401433,0.37221047797551327,null,-0.20849278397401433,-0.7057672031932883,null,-0.20849278397401433,0.25287550776780127,null,0.5177866385883513,0.7014446684711804,null,0.5177866385883513,0.25287550776780127,null,-0.03156946660036224,0.08706232050097786,null,-0.03156946660036224,-0.29568439013002074,null,-0.9913702455959488,-0.7057672031932883,null,-0.9913702455959488,-0.29568439013002074,null,0.25287550776780127,0.764172420550459,null,0.25287550776780127,0.7014446684711804,null,0.25287550776780127,0.37221047797551327,null,0.25287550776780127,-0.20849278397401433,null,0.25287550776780127,0.5177866385883513,null,0.25287550776780127,-0.29568439013002074,null,-0.29568439013002074,0.08706232050097786,null,-0.29568439013002074,-0.4626679443606493,null,-0.29568439013002074,-0.7057672031932883,null,-0.29568439013002074,-0.03156946660036224,null,-0.29568439013002074,-0.9913702455959488,null,-0.29568439013002074,0.25287550776780127,null],\"z\":[0.5044500569850519,0.591988259164906,null,0.5044500569850519,0.358465322304632,null,0.591988259164906,0.5044500569850519,null,0.591988259164906,0.1720503177251114,null,0.591988259164906,0.9999999999999999,null,0.591988259164906,0.358465322304632,null,0.1720503177251114,0.591988259164906,null,0.1720503177251114,-0.49398486964366206,null,0.1720503177251114,0.3435356377588277,null,0.1720503177251114,0.358465322304632,null,-0.49398486964366206,0.1720503177251114,null,-0.49398486964366206,-0.5054420552478749,null,-0.49398486964366206,-0.9963227644992474,null,-0.49398486964366206,-0.37730534558299805,null,-0.5054420552478749,-0.49398486964366206,null,-0.5054420552478749,-0.12349533038007308,null,-0.5054420552478749,-0.37730534558299805,null,-0.12349533038007308,-0.5054420552478749,null,-0.12349533038007308,0.3435356377588277,null,-0.12349533038007308,-0.47393922858467585,null,-0.12349533038007308,-0.37730534558299805,null,0.3435356377588277,0.1720503177251114,null,0.3435356377588277,-0.12349533038007308,null,0.3435356377588277,0.358465322304632,null,0.9999999999999999,0.591988259164906,null,0.9999999999999999,0.358465322304632,null,-0.9963227644992474,-0.49398486964366206,null,-0.9963227644992474,-0.37730534558299805,null,-0.47393922858467585,-0.12349533038007308,null,-0.47393922858467585,-0.37730534558299805,null,0.358465322304632,0.5044500569850519,null,0.358465322304632,0.591988259164906,null,0.358465322304632,0.1720503177251114,null,0.358465322304632,0.3435356377588277,null,0.358465322304632,0.9999999999999999,null,0.358465322304632,-0.37730534558299805,null,-0.37730534558299805,-0.49398486964366206,null,-0.37730534558299805,-0.5054420552478749,null,-0.37730534558299805,-0.12349533038007308,null,-0.37730534558299805,-0.9963227644992474,null,-0.37730534558299805,-0.47393922858467585,null,-0.37730534558299805,0.358465322304632,null],\"type\":\"scatter3d\"},{\"marker\":{\"color\":[\"red\",\"black\",\"black\",\"black\",\"blue\",\"black\",\"red\",\"white\",\"white\",\"white\",\"green\",\"green\"],\"size\":8},\"mode\":\"markers\",\"x\":[0.7537469406528274,0.28449980640302397,-0.1268474548111234,-0.3868052026309772,-0.581799218046257,-0.26180742500821713,-0.10926408143000026,0.4533579629569477,-0.22571230727795144,-0.005591190121949286,0.28077532901629837,-0.07455315970262265],\"y\":[0.764172420550459,0.7014446684711804,0.37221047797551327,0.08706232050097786,-0.4626679443606493,-0.7057672031932883,-0.20849278397401433,0.5177866385883513,-0.03156946660036224,-0.9913702455959488,0.25287550776780127,-0.29568439013002074],\"z\":[0.5044500569850519,0.591988259164906,0.1720503177251114,-0.49398486964366206,-0.5054420552478749,-0.12349533038007308,0.3435356377588277,0.9999999999999999,-0.9963227644992474,-0.47393922858467585,0.358465322304632,-0.37730534558299805],\"type\":\"scatter3d\"}],                        {\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":0},\"scene\":{\"xaxis\":{\"showgrid\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false},\"zaxis\":{\"showgrid\":false,\"showticklabels\":false,\"title\":{\"text\":\"\"},\"zeroline\":false}},\"showlegend\":false,\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1cac08ef-2170-49ed-a98a-751371a6a7c0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Prepare splits for dataset\n",
        "print(f\"Total number of samples: {len(dataset)}.\")\n",
        "\n",
        "# Split datasets (in case of using the full dataset)\n",
        "# test_dataset = dataset[:10000]\n",
        "# val_dataset = dataset[10000:20000]\n",
        "# train_dataset = dataset[20000:]\n",
        "\n",
        "# Split datasets (our 3K subset)\n",
        "train_dataset = dataset[:1000]\n",
        "val_dataset = dataset[1000:2000]\n",
        "test_dataset = dataset[2000:3000]\n",
        "print(f\"Created dataset splits with {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test samples.\")\n",
        "\n",
        "# Create dataloaders with batch size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9mGOS6PVPFp",
        "outputId": "8b6c92d0-bd5d-46b8-d011-5ebc483447cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples: 130831.\n",
            "Created dataset splits with 1000 training, 1000 validation, 1000 test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Rotation/Translation Equivariance Unit Test\n",
        "\n",
        "def rot_trans_equivariance_unit_test(module, dataloader):\n",
        "    \"\"\"Unit test for checking whether a module (GNN layer) is \n",
        "    rotation and translation equivariant.\n",
        "    \"\"\"\n",
        "    it = iter(dataloader)\n",
        "    data = next(it)\n",
        "\n",
        "    out_1, pos_1 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        "\n",
        "    Q = random_orthogonal_matrix(dim=3)\n",
        "    t = torch.rand(3)\n",
        "\n",
        "    # Perform random rotation + translation on data.\n",
        "    data.pos = data.pos @ Q + t\n",
        "\n",
        "    out_2, pos_2 = module(data.x, data.pos, data.edge_index, data.edge_attr)\n",
        " \n",
        "    rotated_pos1 = pos_1@Q + t\n",
        "    return torch.allclose(rotated_pos1, pos_2, atol=1e-04)\n",
        " "
      ],
      "metadata": {
        "id": "FCgfDIu7rwkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E(n) Equivariant MPNN From Satorras et al."
      ],
      "metadata": {
        "id": "E3zQacNIqnN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        Arg?s:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # MLP `\\psi` for computing messages `m_ij`\n",
        "        # Implemented as a stack of Linear->BN->ReLU->Linear->BN->ReLU\n",
        "        # dims: (2d + d_e) -> d\n",
        "        self.mlp_msg = Sequential(\n",
        "            Linear(2*emb_dim + edge_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "        \n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # Implemented as a stack of Linear->BN->ReLU->Linear->BN->ReLU\n",
        "        # dims: 2d -> d\n",
        "        self.mlp_upd = Sequential(\n",
        "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(), \n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        As our MPNNLayer class inherits from the PyG MessagePassing parent class,\n",
        "        we simply need to call the `propagate()` function which starts the \n",
        "        message passing procedure: `message()` -> `aggregate()` -> `update()`.\n",
        "        \n",
        "        The MessagePassing class handles most of the logic for the implementation.\n",
        "        To build custom GNNs, we only need to define our own `message()`, \n",
        "        `aggregate()`, and `update()` functions (defined subsequently).\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: (n, d) - updated node features\n",
        "        \"\"\"\n",
        "\n",
        "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n",
        "        return out\n",
        "\n",
        "    def message(self, h_i, h_j, edge_attr):\n",
        "        \"\"\"Step (1) Message\n",
        "\n",
        "        The `message()` function constructs messages from source nodes j \n",
        "        to destination nodes i for each edge (i, j) in `edge_index`.\n",
        "\n",
        "        The arguments can be a bit tricky to understand: `message()` can take \n",
        "        any arguments that were initially passed to `propagate`. Additionally, \n",
        "        we can differentiate destination nodes and source nodes by appending \n",
        "        `_i` or `_j` to the variable name, e.g. for the node features `h`, we\n",
        "        can use `h_i` and `h_j`. \n",
        "        \n",
        "        This part is critical to understand as the `message()` function\n",
        "        constructs messages for each edge in the graph. The indexing of the\n",
        "        original node features `h` (or other node variables) is handled under\n",
        "        the hood by PyG.\n",
        "\n",
        "        Args:\n",
        "            h_i: (e, d) - destination node features, essentially h[edge_index[0]]\n",
        "            h_j: (e, d) - source node features, essentially h[edge_index[1]]\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "        \n",
        "        Returns:\n",
        "            msg: (e, d) - messages `m_ij` passed through MLP `\\psi`\n",
        "        \"\"\"\n",
        "\n",
        "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
        "        return self.mlp_msg(msg)\n",
        "    \n",
        "    def aggregate(self, inputs, index):\n",
        "        \"\"\"Step (2) Aggregate\n",
        "\n",
        "        The `aggregate` function aggregates the messages from neighboring nodes,\n",
        "        according to the chosen aggregation function ('sum' by default).\n",
        "\n",
        "        Args:\n",
        "            inputs: (e, d) - messages `m_ij` from destination to source nodes\n",
        "            index: (e, 1) - list of source nodes for each edge/message in `input`\n",
        "\n",
        "        Returns:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "        \"\"\"\n",
        "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
        "    \n",
        "    def update(self, aggr_out, h):\n",
        "        \"\"\"\n",
        "        Step (3) Update\n",
        "\n",
        "        The `update()` function computes the final node features by combining the \n",
        "        aggregated messages with the initial node features.\n",
        "\n",
        "        `update()` takes the first argument `aggr_out`, the result of `aggregate()`, \n",
        "        as well as any optional arguments that were initially passed to \n",
        "        `propagate()`. E.g. in this case, we additionally pass `h`.\n",
        "\n",
        "        Args:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "            h: (n, d) - initial node features\n",
        "\n",
        "        Returns:\n",
        "            upd_out: (n, d) - updated node features passed through MLP `\\phi`\n",
        "        \"\"\"\n",
        "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
        "        return self.mlp_upd(upd_out)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')"
      ],
      "metadata": {
        "id": "VcLeUV13mIbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MPNNModel(Module):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=12, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "        \n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "        \n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns: \n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "        \n",
        "        for conv in self.convs:\n",
        "            h = h + conv(h, data.edge_index, data.edge_attr) # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ],
      "metadata": {
        "id": "JevjpzQ9lwLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EquivariantMPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        This layer is equivariant to 3D rotations and translations.\n",
        "\n",
        "        Args:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Define the MLPs constituting your new layer.\n",
        "        # At the least, you will need `\\psi` and `\\phi` \n",
        "        # (but their definitions may be different from what\n",
        "        # we used previously).\n",
        "        #\n",
        "\n",
        "        # MLP `\\psi_m` for computing feature messages `m_ij`\n",
        "        # dims: 2d + d_e + 1 -> d, \n",
        "        # +1 comes from distance btwn nodes\n",
        "\n",
        "\n",
        "        self.mlp_msg = Sequential(\n",
        "            Linear(2*emb_dim + edge_dim + 1, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "        \n",
        "\n",
        "        # MLP `\\psi_x` for computing the weight of relative difference of coord\n",
        "        # dims: d -> 1, \n",
        "        # +1 comes from distance btwn nodes\n",
        "        self.mlp_coord = Linear(emb_dim, 1) #As simple as possible for now\n",
        "        \n",
        "\n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # dims: 2d -> d\n",
        "        self.mlp_upd = Sequential(\n",
        "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(), \n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, h, pos, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            pos: (n, 3) - initial node coordinates\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: [(n, d),(n,3)] - updated node features and coordinates\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Notice that the `forward()` function has a new argument \n",
        "        # `pos` denoting the initial node coordinates. Your task is\n",
        "        # to update the `propagate()` function in order to pass `pos`\n",
        "        # to the `message()` function along with the other arguments.\n",
        "        #\n",
        "\n",
        "        #Same as invariantCoordMPNN\n",
        "        feat_upd, coord_upd = self.propagate(edge_index, h=h, edge_attr = edge_attr, pos = pos)\n",
        "        new_coords = coord_upd + pos\n",
        "        return [feat_upd, new_coords]\n",
        "        # ==========================================\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Write custom `message()`, `aggregate()`, and `update()` functions\n",
        "    # which ensure that the layer is 3D rotation and translation equivariant.\n",
        "    \n",
        "    def message(self, h_i, h_j, pos_i, pos_j, edge_attr):\n",
        "        \"\"\"The `message()` function constructs messages from source nodes j \n",
        "        to destination nodes i for each edge (i, j) in `edge_index`.\n",
        "        \n",
        "        Args:\n",
        "            h_i: (e, d) - destination node features, essentially h[edge_index[0]]\n",
        "            h_j: (e, d) - source node features, essentially h[edge_index[1]]\n",
        "            pos_i: (e, 3) - destination node position, essentially pos[edge_index[0]]\n",
        "            pos_j: (e, 3) - source node position, essentially pos[edge_index[1]]\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "            \n",
        "        Returns:\n",
        "            msg: (e, d) - messages `m_ij` passed through MLP `\\psi`\n",
        "            coord_update: (e, 3)- scalar weighting coefficient times dif in vectors\n",
        "                    (x_i-x_j)*psi_x(m_ij)\n",
        "        \"\"\"\n",
        "\n",
        "        dist = torch.sqrt(torch.sum(torch.pow((pos_i-pos_j),2), dim = 1)).unsqueeze(dim = 1) #Compute L2-norm\n",
        "        msg = torch.cat([h_i, h_j, edge_attr, dist], dim = -1) #has distance now\n",
        "        msg = self.mlp_msg(msg)\n",
        "\n",
        "        coord_weight = self.mlp_coord(msg)\n",
        "        # print(\"coord weight shape:\", coord_weight.shape)\n",
        "        coord_update = (pos_i-pos_j) * coord_weight\n",
        "        # print(\"coord update shape:\", coord_update.shape)\n",
        "        # assert coord_update.shape == [len(msg), 3]\n",
        "        return [msg, coord_update]\n",
        "    \n",
        "    def aggregate(self, inputs, index):\n",
        "        \"\"\"The `aggregate` function aggregates the messages from neighboring nodes,\n",
        "        according to the chosen aggregation function ('sum' by default).\n",
        "\n",
        "        Args:\n",
        "            inputs: [(e, d), (e,3)] - \n",
        "                tuple of:\n",
        "                    [0] messages `m_ij` from destination to source nodes,\n",
        "                    [1] coord messages from destinatoin to source nodes\n",
        "            index: (e, 1) - list of source nodes for each edge/message in `input`\n",
        "\n",
        "        Returns:\n",
        "            feat_out: (n, d) - aggregated messages `m_i`\n",
        "            coord_out: (n, 3) - aggregated coordinate update \n",
        "        \"\"\"\n",
        "\n",
        "        feat_out = scatter(inputs[0], index, dim=self.node_dim, reduce=self.aggr)\n",
        "        coord_out = scatter(inputs[1], index, dim=self.node_dim, reduce= 'mean') \n",
        "        #I believe mean is same here as the original paper, which sums then \n",
        "        #divides by number of elements\n",
        "\n",
        "\n",
        "        return [feat_out, coord_out]\n",
        "\n",
        "    def update(self, inputs, h):\n",
        "        \"\"\"The `update()` function computes the final node features by combining the \n",
        "        aggregated messages with the initial node features.\n",
        "\n",
        "        Args:\n",
        "            inputs: [(e, d), (e,3)] - \n",
        "                tuple of:\n",
        "                    [0] aggregated messages `m_i`\n",
        "                    [1] aggregated coordinate updates\n",
        "            h: (n, d) - initial node features\n",
        "\n",
        "        Returns:\n",
        "            upd_feat: (n, d) - updated node features passed through MLP `\\phi`\n",
        "            upd_coord: (n, d) - updated node coordinates from aggregator\n",
        "        \"\"\"\n",
        "        upd_feat = torch.cat([h, inputs[0]], dim=-1)\n",
        "        upd_feat = self.mlp_upd(upd_feat)\n",
        "\n",
        "        upd_coord = inputs[1]\n",
        "        assert upd_coord.shape[1] == 3\n",
        "        return [upd_feat, upd_coord]\n",
        "    # ==========================================\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
        "\n",
        "\n",
        "class FinalMPNNModel(MPNNModel):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=12, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        This model uses both node features and coordinates as inputs, and\n",
        "        is invariant to 3D rotations and translations (the constituent MPNN layers\n",
        "        are equivariant to 3D rotations and translations).\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "        \n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "        \n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns: \n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "        pos = data.pos\n",
        "        \n",
        "        for conv in self.convs:\n",
        "            # Message passing layer\n",
        "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
        "            \n",
        "            # Update node features\n",
        "            h = h + h_update # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "            \n",
        "            # Update node coordinates\n",
        "            pos = pos_update # (n, 3) -> (n, 3)\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ],
      "metadata": {
        "id": "aU5IjayDlLab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS = {}\n",
        "DF_RESULTS = pd.DataFrame(columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])"
      ],
      "metadata": {
        "id": "q45xuBOXmmq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "layer = EquivariantMPNNLayer(emb_dim=11, edge_dim=4)\n",
        "model = FinalMPNNModel(num_layers=4, emb_dim=64, in_dim=12, edge_dim=4, out_dim=1)\n",
        "# ==========================================\n",
        "\n",
        "model_name = type(model).__name__\n",
        "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
        "    model, \n",
        "    model_name, # \"MPNN w/ Features and Coordinates (Equivariant Layers)\", \n",
        "    train_loader,\n",
        "    val_loader, \n",
        "    test_loader,\n",
        "    n_epochs=100\n",
        ")\n",
        "\n",
        "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
        "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
        "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLX-sJGRmN3d",
        "outputId": "95571b9a-964f-4b35-f779-0ace5a53e29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running experiment for FinalMPNNModel, training on 1000 samples for 100 epochs.\n",
            "\n",
            "Model architecture:\n",
            "FinalMPNNModel(\n",
            "  (lin_in): Linear(in_features=12, out_features=64, bias=True)\n",
            "  (convs): ModuleList(\n",
            "    (0-3): 4 x EquivariantMPNNLayer(emb_dim=64, aggr=add)\n",
            "  )\n",
            "  (lin_pred): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Total parameters: 103813\n",
            "\n",
            "Start training:\n",
            "Epoch: 010, LR: 0.001000, Loss: 0.4207803, Val MAE: 0.8707978, Test MAE: 0.6727469\n",
            "Epoch: 020, LR: 0.000900, Loss: 0.2808954, Val MAE: 0.8504293, Test MAE: 0.6207397\n",
            "Epoch: 030, LR: 0.000810, Loss: 0.1946441, Val MAE: 0.7036817, Test MAE: 0.5423659\n",
            "Epoch: 040, LR: 0.000729, Loss: 0.0822185, Val MAE: 0.6763496, Test MAE: 0.5817720\n",
            "Epoch: 050, LR: 0.000656, Loss: 0.0968526, Val MAE: 0.7106811, Test MAE: 0.5817720\n",
            "Epoch: 060, LR: 0.000590, Loss: 0.0618200, Val MAE: 0.6638162, Test MAE: 0.5559601\n",
            "Epoch: 070, LR: 0.000590, Loss: 0.0501357, Val MAE: 0.7135672, Test MAE: 0.5536521\n",
            "Epoch: 080, LR: 0.000478, Loss: 0.0926983, Val MAE: 0.6836134, Test MAE: 0.5536521\n",
            "Epoch: 090, LR: 0.000430, Loss: 0.0323399, Val MAE: 0.6806721, Test MAE: 0.5571893\n",
            "Epoch: 100, LR: 0.000349, Loss: 0.0258396, Val MAE: 0.6679182, Test MAE: 0.5571893\n",
            "\n",
            "Done! Training took 19.20 mins. Best validation MAE: 0.6551087, corresponding test MAE: 0.5571893.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom MPNN that optionally looks at coordinate information of virtual nodes"
      ],
      "metadata": {
        "id": "YQBzs7QGq38j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VirtualEquivariantMPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        This layer is equivariant to 3D rotations and translations.\n",
        "\n",
        "        This layer optionally will use coordinate information \n",
        "\n",
        "        Args:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Define the MLPs constituting your new layer.\n",
        "        # At the least, you will need `\\psi` and `\\phi` \n",
        "        # (but their definitions may be different from what\n",
        "        # we used previously).\n",
        "        #\n",
        "\n",
        "        # MLP `\\psi_m` for computing feature messages `m_ij`\n",
        "        # dims: 2d + d_e + 1 -> d, \n",
        "        # +1 comes from distance btwn nodes\n",
        "\n",
        "\n",
        "        self.mlp_msg = Sequential(\n",
        "            Linear(2*emb_dim + edge_dim + 1, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "        \n",
        "\n",
        "        # MLP `\\psi_x` for computing the weight of relative difference of coord\n",
        "        # dims: d -> 1, \n",
        "        # +1 comes from distance btwn nodes\n",
        "        self.mlp_coord = Linear(emb_dim, 1) #As simple as possible for now\n",
        "        \n",
        "\n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # dims: 2d -> d\n",
        "        self.mlp_upd = Sequential(\n",
        "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(), \n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, h, pos, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            pos: (n, 3) - initial node coordinates\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: [(n, d),(n,3)] - updated node features and coordinates\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Notice that the `forward()` function has a new argument \n",
        "        # `pos` denoting the initial node coordinates. Your task is\n",
        "        # to update the `propagate()` function in order to pass `pos`\n",
        "        # to the `message()` function along with the other arguments.\n",
        "        #\n",
        "\n",
        "        #Same as invariantCoordMPNN\n",
        "        feat_upd, coord_upd = self.propagate(edge_index, h=h, edge_attr = edge_attr, pos = pos)\n",
        "        new_coords = coord_upd + pos\n",
        "        return [feat_upd, new_coords]\n",
        "        # ==========================================\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Write custom `message()`, `aggregate()`, and `update()` functions\n",
        "    # which ensure that the layer is 3D rotation and translation equivariant.\n",
        "    \n",
        "    def message(self, h_i, h_j, pos_i, pos_j, edge_attr):\n",
        "        \"\"\"The `message()` function constructs messages from source nodes j \n",
        "        to destination nodes i for each edge (i, j) in `edge_index`.\n",
        "        \n",
        "        Args:\n",
        "            h_i: (e, d) - destination node features, essentially h[edge_index[0]]\n",
        "            h_j: (e, d) - source node features, essentially h[edge_index[1]]\n",
        "            pos_i: (e, 3) - destination node position, essentially pos[edge_index[0]]\n",
        "            pos_j: (e, 3) - source node position, essentially pos[edge_index[1]]\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "            \n",
        "        Returns:\n",
        "            msg: (e, d) - messages `m_ij` passed through MLP `\\psi`\n",
        "            coord_update: (e, 3)- scalar weighting coefficient times dif in vectors\n",
        "                    (x_i-x_j)*psi_x(m_ij)\n",
        "        \"\"\"\n",
        "\n",
        "        dist = torch.sqrt(torch.sum(torch.pow((pos_i-pos_j),2), dim = 1)).unsqueeze(dim = 1) #Compute L2-norm\n",
        "        msg = torch.cat([h_i, h_j, edge_attr, dist], dim = -1) #has distance now\n",
        "        msg = self.mlp_msg(msg)\n",
        "\n",
        "        coord_weight = self.mlp_coord(msg)\n",
        "        # print(\"coord weight shape:\", coord_weight.shape)\n",
        "        coord_update = (pos_i-pos_j) * coord_weight\n",
        "        # print(\"coord update shape:\", coord_update.shape)\n",
        "        # assert coord_update.shape == [len(msg), 3]\n",
        "        return [msg, coord_update]\n",
        "    \n",
        "    def aggregate(self, inputs, index):\n",
        "        \"\"\"The `aggregate` function aggregates the messages from neighboring nodes,\n",
        "        according to the chosen aggregation function ('sum' by default).\n",
        "\n",
        "        Args:\n",
        "            inputs: [(e, d), (e,3)] - \n",
        "                tuple of:\n",
        "                    [0] messages `m_ij` from destination to source nodes,\n",
        "                    [1] coord messages from destinatoin to source nodes\n",
        "            index: (e, 1) - list of source nodes for each edge/message in `input`\n",
        "\n",
        "        Returns:\n",
        "            feat_out: (n, d) - aggregated messages `m_i`\n",
        "            coord_out: (n, 3) - aggregated coordinate update \n",
        "        \"\"\"\n",
        "\n",
        "        feat_out = scatter(inputs[0], index, dim=self.node_dim, reduce=self.aggr)\n",
        "        coord_out = scatter(inputs[1], index, dim=self.node_dim, reduce= 'mean') \n",
        "        #I believe mean is same here as the original paper, which sums then \n",
        "        #divides by number of elements\n",
        "\n",
        "\n",
        "        return [feat_out, coord_out]\n",
        "\n",
        "    def update(self, inputs, h):\n",
        "        \"\"\"The `update()` function computes the final node features by combining the \n",
        "        aggregated messages with the initial node features.\n",
        "\n",
        "        Args:\n",
        "            inputs: [(e, d), (e,3)] - \n",
        "                tuple of:\n",
        "                    [0] aggregated messages `m_i`\n",
        "                    [1] aggregated coordinate updates\n",
        "            h: (n, d) - initial node features\n",
        "\n",
        "        Returns:\n",
        "            upd_feat: (n, d) - updated node features passed through MLP `\\phi`\n",
        "            upd_coord: (n, d) - updated node coordinates from aggregator\n",
        "        \"\"\"\n",
        "        upd_feat = torch.cat([h, inputs[0]], dim=-1)\n",
        "        upd_feat = self.mlp_upd(upd_feat)\n",
        "\n",
        "        upd_coord = inputs[1]\n",
        "        assert upd_coord.shape[1] == 3\n",
        "        return [upd_feat, upd_coord]\n",
        "    # ==========================================\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
        "\n",
        "\n",
        "class FinalMPNNModel(MPNNModel):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=12, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        This model uses both node features and coordinates as inputs, and\n",
        "        is invariant to 3D rotations and translations (the constituent MPNN layers\n",
        "        are equivariant to 3D rotations and translations).\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "        \n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "        \n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns: \n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "        pos = data.pos\n",
        "        \n",
        "        for conv in self.convs:\n",
        "            # Message passing layer\n",
        "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
        "            \n",
        "            # Update node features\n",
        "            h = h + h_update # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "            \n",
        "            # Update node coordinates\n",
        "            pos = pos_update # (n, 3) -> (n, 3)\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ],
      "metadata": {
        "id": "UQG1ccUGrDnu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}